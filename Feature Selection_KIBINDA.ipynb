{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: Forward and Backward Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will go through implementing Wrapper Models for feature Selection. We will work on a  Linear Regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avgAnnCount</th>\n",
       "      <th>avgDeathsPerYear</th>\n",
       "      <th>TARGET_deathRate</th>\n",
       "      <th>incidenceRate</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>popEst2015</th>\n",
       "      <th>povertyPercent</th>\n",
       "      <th>studyPerCap</th>\n",
       "      <th>MedianAge</th>\n",
       "      <th>MedianAgeMale</th>\n",
       "      <th>...</th>\n",
       "      <th>PctMarriedHouseholds-8</th>\n",
       "      <th>PctMarriedHouseholds-9</th>\n",
       "      <th>BirthRate-2</th>\n",
       "      <th>BirthRate-3</th>\n",
       "      <th>BirthRate-4</th>\n",
       "      <th>BirthRate-5</th>\n",
       "      <th>BirthRate-6</th>\n",
       "      <th>BirthRate-7</th>\n",
       "      <th>BirthRate-8</th>\n",
       "      <th>BirthRate-9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1397.0</td>\n",
       "      <td>469</td>\n",
       "      <td>164.9</td>\n",
       "      <td>489.8</td>\n",
       "      <td>61898</td>\n",
       "      <td>260131</td>\n",
       "      <td>11.2</td>\n",
       "      <td>499.748204</td>\n",
       "      <td>39.3</td>\n",
       "      <td>36.9</td>\n",
       "      <td>...</td>\n",
       "      <td>6.091992e+13</td>\n",
       "      <td>3.219988e+15</td>\n",
       "      <td>37.440093</td>\n",
       "      <td>229.089604</td>\n",
       "      <td>1401.760576</td>\n",
       "      <td>8577.136107</td>\n",
       "      <td>52482.046553</td>\n",
       "      <td>321128.774915</td>\n",
       "      <td>1.964933e+06</td>\n",
       "      <td>1.202309e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173.0</td>\n",
       "      <td>70</td>\n",
       "      <td>161.3</td>\n",
       "      <td>411.6</td>\n",
       "      <td>48127</td>\n",
       "      <td>43269</td>\n",
       "      <td>18.6</td>\n",
       "      <td>23.111234</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.796146e+13</td>\n",
       "      <td>8.149565e+14</td>\n",
       "      <td>18.775717</td>\n",
       "      <td>81.356978</td>\n",
       "      <td>352.527560</td>\n",
       "      <td>1527.535610</td>\n",
       "      <td>6618.957797</td>\n",
       "      <td>28680.576760</td>\n",
       "      <td>1.242757e+05</td>\n",
       "      <td>5.384984e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.0</td>\n",
       "      <td>50</td>\n",
       "      <td>174.7</td>\n",
       "      <td>349.7</td>\n",
       "      <td>49348</td>\n",
       "      <td>21026</td>\n",
       "      <td>14.6</td>\n",
       "      <td>47.560164</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.720681e+13</td>\n",
       "      <td>4.203515e+15</td>\n",
       "      <td>13.909079</td>\n",
       "      <td>51.873742</td>\n",
       "      <td>193.462489</td>\n",
       "      <td>721.515996</td>\n",
       "      <td>2690.885118</td>\n",
       "      <td>10035.623263</td>\n",
       "      <td>3.742773e+04</td>\n",
       "      <td>1.395863e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>427.0</td>\n",
       "      <td>202</td>\n",
       "      <td>194.8</td>\n",
       "      <td>430.4</td>\n",
       "      <td>44243</td>\n",
       "      <td>75882</td>\n",
       "      <td>17.1</td>\n",
       "      <td>342.637253</td>\n",
       "      <td>42.8</td>\n",
       "      <td>42.2</td>\n",
       "      <td>...</td>\n",
       "      <td>4.592263e+13</td>\n",
       "      <td>2.343042e+15</td>\n",
       "      <td>21.195350</td>\n",
       "      <td>97.580016</td>\n",
       "      <td>449.242856</td>\n",
       "      <td>2068.242577</td>\n",
       "      <td>9521.859503</td>\n",
       "      <td>43837.125013</td>\n",
       "      <td>2.018191e+05</td>\n",
       "      <td>9.291432e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>26</td>\n",
       "      <td>144.4</td>\n",
       "      <td>350.1</td>\n",
       "      <td>49955</td>\n",
       "      <td>10321</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.3</td>\n",
       "      <td>47.8</td>\n",
       "      <td>...</td>\n",
       "      <td>7.259662e+13</td>\n",
       "      <td>3.922211e+15</td>\n",
       "      <td>46.194552</td>\n",
       "      <td>313.968540</td>\n",
       "      <td>2133.936595</td>\n",
       "      <td>14503.635908</td>\n",
       "      <td>98576.244063</td>\n",
       "      <td>669988.956897</td>\n",
       "      <td>4.553685e+06</td>\n",
       "      <td>3.094984e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avgAnnCount  avgDeathsPerYear  TARGET_deathRate  incidenceRate  medIncome  \\\n",
       "0       1397.0               469             164.9          489.8      61898   \n",
       "1        173.0                70             161.3          411.6      48127   \n",
       "2        102.0                50             174.7          349.7      49348   \n",
       "3        427.0               202             194.8          430.4      44243   \n",
       "4         57.0                26             144.4          350.1      49955   \n",
       "\n",
       "   popEst2015  povertyPercent  studyPerCap  MedianAge  MedianAgeMale  ...  \\\n",
       "0      260131            11.2   499.748204       39.3           36.9  ...   \n",
       "1       43269            18.6    23.111234       33.0           32.2  ...   \n",
       "2       21026            14.6    47.560164       45.0           44.0  ...   \n",
       "3       75882            17.1   342.637253       42.8           42.2  ...   \n",
       "4       10321            12.5     0.000000       48.3           47.8  ...   \n",
       "\n",
       "   PctMarriedHouseholds-8  PctMarriedHouseholds-9  BirthRate-2  BirthRate-3  \\\n",
       "0            6.091992e+13            3.219988e+15    37.440093   229.089604   \n",
       "1            1.796146e+13            8.149565e+14    18.775717    81.356978   \n",
       "2            7.720681e+13            4.203515e+15    13.909079    51.873742   \n",
       "3            4.592263e+13            2.343042e+15    21.195350    97.580016   \n",
       "4            7.259662e+13            3.922211e+15    46.194552   313.968540   \n",
       "\n",
       "   BirthRate-4   BirthRate-5   BirthRate-6    BirthRate-7   BirthRate-8  \\\n",
       "0  1401.760576   8577.136107  52482.046553  321128.774915  1.964933e+06   \n",
       "1   352.527560   1527.535610   6618.957797   28680.576760  1.242757e+05   \n",
       "2   193.462489    721.515996   2690.885118   10035.623263  3.742773e+04   \n",
       "3   449.242856   2068.242577   9521.859503   43837.125013  2.018191e+05   \n",
       "4  2133.936595  14503.635908  98576.244063  669988.956897  4.553685e+06   \n",
       "\n",
       "    BirthRate-9  \n",
       "0  1.202309e+07  \n",
       "1  5.384984e+05  \n",
       "2  1.395863e+05  \n",
       "3  9.291432e+05  \n",
       "4  3.094984e+07  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('cancer-mortality-rate.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3047, 280)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cl = data.columns\n",
    "# for i in cl:\n",
    "#     if data[i].isna().sum()!=0:\n",
    "#         print(\"la colonne {} a {} nan values\".format(i,data[i].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: PctSomeCol18_24, Number of nan value: 2285\n",
      "Col: PctEmployed16_Over, Number of nan value: 152\n",
      "Col: PctPrivateCoverageAlone, Number of nan value: 609\n",
      "Col: PctSomeCol18_24-2, Number of nan value: 2285\n",
      "Col: PctSomeCol18_24-3, Number of nan value: 2285\n",
      "Col: PctSomeCol18_24-4, Number of nan value: 2285\n",
      "Col: PctSomeCol18_24-5, Number of nan value: 2285\n",
      "Col: PctSomeCol18_24-6, Number of nan value: 2285\n",
      "Col: PctSomeCol18_24-7, Number of nan value: 2285\n",
      "Col: PctSomeCol18_24-8, Number of nan value: 2285\n",
      "Col: PctSomeCol18_24-9, Number of nan value: 2285\n",
      "Col: PctEmployed16_Over-2, Number of nan value: 152\n",
      "Col: PctEmployed16_Over-3, Number of nan value: 152\n",
      "Col: PctEmployed16_Over-4, Number of nan value: 152\n",
      "Col: PctEmployed16_Over-5, Number of nan value: 152\n",
      "Col: PctEmployed16_Over-6, Number of nan value: 152\n",
      "Col: PctEmployed16_Over-7, Number of nan value: 152\n",
      "Col: PctEmployed16_Over-8, Number of nan value: 152\n",
      "Col: PctEmployed16_Over-9, Number of nan value: 152\n",
      "Col: PctPrivateCoverageAlone-2, Number of nan value: 609\n",
      "Col: PctPrivateCoverageAlone-3, Number of nan value: 609\n",
      "Col: PctPrivateCoverageAlone-4, Number of nan value: 609\n",
      "Col: PctPrivateCoverageAlone-5, Number of nan value: 609\n",
      "Col: PctPrivateCoverageAlone-6, Number of nan value: 609\n",
      "Col: PctPrivateCoverageAlone-7, Number of nan value: 609\n",
      "Col: PctPrivateCoverageAlone-8, Number of nan value: 609\n",
      "Col: PctPrivateCoverageAlone-9, Number of nan value: 609\n"
     ]
    }
   ],
   "source": [
    "#Check Nan values\n",
    "for col in data.columns:\n",
    "    if data[col].isna().sum()!=0:\n",
    "        print(f\"Col: {col}, Number of nan value: {data[col].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-154-c566dc43fe4c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col][data[col].isna()] = data[col].mean()\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    if data[col].isna().sum()!=0:\n",
    "        data[col][data[col].isna()] = data[col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['TARGET_deathRate']\n",
    "X = data.drop(columns=['TARGET_deathRate'])\n",
    "normalized_X = (X - X.mean()) / X.std()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(normalized_X, y, test_size = .2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Fit a LR model on all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  112255.8675650906\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_pred, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=42, shuffle=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, random_state= 42)\n",
    "print(kf)  \n",
    "\n",
    "# KFold training helper function\n",
    "def KFold_train(model, X, Y, kf):\n",
    "    scores = []\n",
    "    for train_index, val_index in kf.split(X): #we split the train to KFold cross validate\n",
    "        x_train, x_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = Y[train_index], Y[val_index]\n",
    "        model.fit(x_train, y_train)\n",
    "        pred_y = model.predict(x_val)\n",
    "        scores.append(mean_squared_error(y_val, pred_y)**.5)\n",
    "    \n",
    "    return np.mean(np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection greedy methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2437, 279), (610, 279), (2437,), (610,))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 -  Forward Search\n",
    "<img src='forward.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def forward_search(model, K, X, Y):\n",
    "    \n",
    "    rmse_losses = []\n",
    "    best_losses = []\n",
    "    set_features = []\n",
    "    all_scores = []\n",
    "    \n",
    "    ### get all the features of the data\n",
    "    features =  list(X.columns)\n",
    "    i = 1 # this index handles the case of one feature where reshaping is needed (do not care about it)\n",
    "    while len(set_features) <= K:\n",
    "        rmse_losses = []\n",
    "\n",
    "        for feature in features:\n",
    "\n",
    "            # Extract X with the subset of features\n",
    "            new_feature = [feature] + set_features\n",
    "\n",
    "            # Extract X with the subset of new features\n",
    "            new_data = X[new_feature].values\n",
    "            \n",
    "            #split the new_data in train and validation(test_size = 20%)\n",
    "            x_train, x_val, y_train, y_val = train_test_split(new_data, Y.values, test_size = 0.2, random_state =123)\n",
    "\n",
    "            if i == 1:\n",
    "                x_train = x_train.reshape(-1, 1)\n",
    "                x_val = x_val.reshape(-1, 1)\n",
    "\n",
    "            #Cross validation using the KFold_train function\n",
    "            scores= KFold_train(model, x_train, y_train, kf)\n",
    "            \n",
    "            # Fit the model on the training set\n",
    "            model.fit(x_train,y_train) ## Replace with your code\n",
    "            \n",
    "            #Make Prediction on the validation set\n",
    "            ypred = model.predict(x_val) \n",
    "\n",
    "            #Calculate the RMSE on the validation set\n",
    "            rmse_loss = np.sqrt(mean_squared_error(ypred, y_val))\n",
    "\n",
    "            rmse_losses.append(rmse_loss)\n",
    "        \n",
    "        i += 1\n",
    "        #select feature that give the best RMSE\n",
    "        present_best_feature = features[np.argmin(rmse_losses)]# None\n",
    "        \n",
    "        #remove that present best feature from the initial set of input features, we will not include it again\n",
    "        features.remove(features[np.argmin(rmse_losses)]) ### replace with your code### #del features[np.argmin(rmse_losses)]\n",
    "        \n",
    "        \n",
    "        #add the present best feature to set_features\n",
    "        set_features.append(present_best_feature) ### replace with your code###\n",
    "        \n",
    "        all_scores.append(np.mean(scores))\n",
    "        best_losses.append(np.min(rmse_losses))\n",
    "        print('K=',len(set_features),':',set_features, ' || RMSE: ', np.min(rmse_losses) )\n",
    "    return set_features,all_scores,best_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 1 : ['PctBachDeg25_Over']  || RMSE:  22.662049885228207\n",
      "K= 2 : ['PctBachDeg25_Over', 'incidenceRate']  || RMSE:  19.953431283868007\n",
      "K= 3 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2']  || RMSE:  19.039811170721464\n",
      "K= 4 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8']  || RMSE:  18.798883392570474\n",
      "K= 5 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over']  || RMSE:  18.57963992023238\n",
      "K= 6 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over', 'PctSomeCol18_24-9']  || RMSE:  18.331880650948897\n",
      "K= 7 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over', 'PctSomeCol18_24-9', 'MedianAgeFemale-5']  || RMSE:  18.256059364321825\n",
      "K= 8 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over', 'PctSomeCol18_24-9', 'MedianAgeFemale-5', 'PctOtherRace']  || RMSE:  18.141961180195473\n",
      "K= 9 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over', 'PctSomeCol18_24-9', 'MedianAgeFemale-5', 'PctOtherRace', 'PctOtherRace-2']  || RMSE:  18.0456324772012\n",
      "K= 10 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over', 'PctSomeCol18_24-9', 'MedianAgeFemale-5', 'PctOtherRace', 'PctOtherRace-2', 'PctWhite-7']  || RMSE:  17.96432459812644\n",
      "K= 11 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over', 'PctSomeCol18_24-9', 'MedianAgeFemale-5', 'PctOtherRace', 'PctOtherRace-2', 'PctWhite-7', 'BirthRate-2']  || RMSE:  17.880124186980993\n",
      "K= 12 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over', 'PctSomeCol18_24-9', 'MedianAgeFemale-5', 'PctOtherRace', 'PctOtherRace-2', 'PctWhite-7', 'BirthRate-2', 'PctBlack-2']  || RMSE:  17.814108152854278\n",
      "K= 13 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over', 'PctSomeCol18_24-9', 'MedianAgeFemale-5', 'PctOtherRace', 'PctOtherRace-2', 'PctWhite-7', 'BirthRate-2', 'PctBlack-2', 'PctOtherRace-7']  || RMSE:  17.74385002907328\n",
      "K= 14 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over', 'PctSomeCol18_24-9', 'MedianAgeFemale-5', 'PctOtherRace', 'PctOtherRace-2', 'PctWhite-7', 'BirthRate-2', 'PctBlack-2', 'PctOtherRace-7', 'PctUnemployed16_Over']  || RMSE:  17.69553005743482\n",
      "K= 15 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over', 'PctSomeCol18_24-9', 'MedianAgeFemale-5', 'PctOtherRace', 'PctOtherRace-2', 'PctWhite-7', 'BirthRate-2', 'PctBlack-2', 'PctOtherRace-7', 'PctUnemployed16_Over', 'popEst2015-6']  || RMSE:  17.6621092048854\n",
      "K= 16 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over', 'PctSomeCol18_24-9', 'MedianAgeFemale-5', 'PctOtherRace', 'PctOtherRace-2', 'PctWhite-7', 'BirthRate-2', 'PctBlack-2', 'PctOtherRace-7', 'PctUnemployed16_Over', 'popEst2015-6', 'PctPublicCoverage-7']  || RMSE:  17.628061280105477\n",
      "K= 17 : ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over', 'PctSomeCol18_24-9', 'MedianAgeFemale-5', 'PctOtherRace', 'PctOtherRace-2', 'PctWhite-7', 'BirthRate-2', 'PctBlack-2', 'PctOtherRace-7', 'PctUnemployed16_Over', 'popEst2015-6', 'PctPublicCoverage-7', 'PctHS25_Over-2']  || RMSE:  17.60220369452627\n"
     ]
    }
   ],
   "source": [
    "### Let us fix a value of K, in this case k = d**.5\n",
    "K = int(X.shape[1]**.5)\n",
    "lr = LinearRegression()\n",
    "best_features, scores, best_losses = forward_search(lr, K, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Features from Forward Search:  ['PctBachDeg25_Over', 'incidenceRate', 'povertyPercent-2', 'PercentMarried-8', 'PctHS25_Over', 'PctSomeCol18_24-9', 'MedianAgeFemale-5', 'PctOtherRace', 'PctOtherRace-2', 'PctWhite-7', 'BirthRate-2', 'PctBlack-2', 'PctOtherRace-7', 'PctUnemployed16_Over', 'popEst2015-6', 'PctPublicCoverage-7', 'PctHS25_Over-2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fee0fd10520>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Best Features from Forward Search: ',best_features)\n",
    "plt.plot(best_losses, label='Loss on Validation')\n",
    "plt.plot(scores, label='Estimation on GE')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('RMSE Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Test Loss:  32.6481332287578\n"
     ]
    }
   ],
   "source": [
    "### Make prediction on our Test Set with the new set of features\n",
    "test_pred = lr.predict(X_test[best_features])\n",
    "\n",
    "### Compute the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(test_pred, Y_test))\n",
    "print('RMSE Test Loss: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Backward Search\n",
    "\n",
    "Backward search\n",
    "starts off with F = {1, . . . , d} as the set of all features\n",
    "1. Train the model with all the features\n",
    "\n",
    "2. repeatedly delete features one at a time (evaluating single-feature deletions in a similar manner to how forward search evaluates single-feature additions) until F = ∅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def backward_search(model, X, Y, K):\n",
    "    \n",
    "    ### get the features of the data\n",
    "    features = X.columns.tolist()\n",
    "    \n",
    "    rmse_losses = []\n",
    "    best_losses = []\n",
    "    best_features = []\n",
    "    subset_feature = features\n",
    "    all_scores = []\n",
    "    \n",
    "    while len(subset_feature) > K:\n",
    "        all_poss_features = []\n",
    "        rmse_losses = []\n",
    "        for feature in features:\n",
    "            subset_feature = features.copy()\n",
    "            subset_feature.remove(feature)\n",
    "\n",
    "            # Extract X with the subset of new features\n",
    "            new_data = X[subset_feature].values\n",
    "            \n",
    "            #split the new_data in train and validation(test_size = 20%)\n",
    "            x_train, x_val, y_train, y_val = train_test_split(new_data, Y.values, test_size = 0.2, random_state = 123)\n",
    "\n",
    "            y_train = y_train.reshape(-1, 1)\n",
    "            y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "            #Cross validation using the KFold_train function\n",
    "            scores= KFold_train(model, x_train, y_train, kf)\n",
    "            \n",
    "             # Fit the model on the training set\n",
    "            model.fit(x_train,y_train) ## Replace with your code\n",
    "            \n",
    "            #Make Prediction on the validation set\n",
    "            ypred = model.predict(x_val) \n",
    "\n",
    "            #Calculate the RMSE on the validation set\n",
    "            rmse_loss = np.sqrt(mean_squared_error(ypred, y_val))\n",
    "\n",
    "            rmse_losses.append(rmse_loss)\n",
    "            all_poss_features.append(subset_feature)\n",
    "    \n",
    "        #Remove the feature f_i that, when eliminated, gives the best RMSE so far.\n",
    "        #ie if F-{f_i} gives the best RMSE so far, f_i will not be considered again on next iterations\n",
    "        feature_to_eliminate = features[np.argmin(rmse_losses)]\n",
    "        \n",
    "        #remove that feature from the initial set of input features\n",
    "        features.remove(features[np.argmin(rmse_losses)]) ### replace with your code###\n",
    "          \n",
    "        best_features.append(all_poss_features[np.argmin(rmse_losses)])\n",
    "        all_scores.append(np.mean(scores))\n",
    "        best_losses.append(np.min(rmse_losses))\n",
    "    return best_features, best_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 250\n",
    "lr = LinearRegression()\n",
    "best_features, best_losses = backward_search(lr, X_train, Y_train, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Features from Backward Search: ', best_features)\n",
    "plt.plot(best_losses, label='Loss on Validation')\n",
    "plt.plot(scores, label='Estimation on G.E.')\n",
    "plt.xlabel('K')\n",
    "plt.label('RMSE Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make prediction on our Test Set with the new set of features\n",
    "test_pred = lr.predict()\n",
    "\n",
    "### Compute the RMSE\n",
    "rmse = None\n",
    "print('RMSE Test Loss: ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Missing Value Ratio</b> is a filter method for Feature Selection that drops all the features that have a number of missing values greater than a certain threshold. \n",
    "Can you implement it using this previous dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
